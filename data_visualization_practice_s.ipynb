{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c340db",
   "metadata": {},
   "source": [
    "# Практика визуализации данных - датасет Open Food Facts\n",
    "\n",
    "## Добро пожаловать на практическое занятие!\n",
    "\n",
    "После изучения различных техник визуализации на лекции с датасетом Iris, пришло время применить эти навыки к реальному датасету. Сегодня мы будем работать с датасетом **Open Food Facts** - коллаборативной базой данных пищевых продуктов со всего мира.\n",
    "\n",
    "### Цели обучения:\n",
    "- Применить техники визуализации, изученные на лекции\n",
    "- Работать с большим, более сложным реальным датасетом\n",
    "- Практиковать очистку и предобработку данных\n",
    "- Создавать осмысленные выводы из данных пищевой промышленности\n",
    "\n",
    "### О датасете Open Food Facts:\n",
    "База данных Open Food Facts содержит информацию о пищевых продуктах, включая:\n",
    "- **Пищевую ценность** (калории, белки, жиры, углеводы)\n",
    "- **Категории продуктов** (напитки, закуски, молочные продукты и т.д.)\n",
    "- **Ингредиенты и добавки**\n",
    "- **Nutri-Score** (рейтинг пищевой ценности A-E)\n",
    "- **Географическую информацию** (страны, бренды)\n",
    "\n",
    "### Источник датасета:\n",
    "- **URL:** https://world.openfoodfacts.org/\n",
    "- **Файл:** en.openfoodfacts.org.products.tsv\n",
    "- **Формат:** Значения, разделенные табуляцией (TSV)\n",
    "- **Размер:** Несколько сотен тысяч продуктов\n",
    "\n",
    "### Что вы будете практиковать:\n",
    "1. **Загрузка и исследование данных** - Понимание структуры датасета\n",
    "2. **Базовая визуализация** - Диаграммы рассеяния, гистограммы, коробчатые диаграммы\n",
    "3. **Продвинутые техники** - Многомерный анализ, корреляции\n",
    "4. **Реальные выводы** - Анализ питания, сравнение брендов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d94f8",
   "metadata": {},
   "source": [
    "## Настройка - Импорт библиотек\n",
    "\n",
    "**Инструкции:** Выполните ячейку ниже для импорта всех необходимых библиотек для нашего анализа. Это те же библиотеки, которые мы использовали на лекции, плюс несколько дополнительных для работы с большими датасетами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57afafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все библиотеки успешно импортированы!\n",
      "Готовы начать практику визуализации данных!\n"
     ]
    }
   ],
   "source": [
    "# Импорт основных библиотек для анализа данных и визуализации\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Библиотеки для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import andrews_curves, parallel_coordinates, radviz\n",
    "\n",
    "# Настройка параметров визуализации\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Настройки отображения для лучшего вывода\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Все библиотеки успешно импортированы!\")\n",
    "print(\"Готовы начать практику визуализации данных!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02424f",
   "metadata": {},
   "source": [
    "## Упражнение 1: Загрузка данных и первичное исследование\n",
    "\n",
    "### Инструкции:\n",
    "1. **Скачайте датасет** с https://world.openfoodfacts.org/ (en.openfoodfacts.org.products.tsv)\n",
    "2. **Поместите файл** в ту же директорию, что и этот блокнот\n",
    "3. **Загрузите данные** используя pandas (файл разделен табуляцией, используйте `sep='\\t'`)\n",
    "4. **Исследуйте базовые свойства** датасета\n",
    "\n",
    "### Ваши задачи:\n",
    "- Загрузить датасет в pandas DataFrame\n",
    "- Отобразить первые несколько строк\n",
    "- Проверить форму (количество строк и столбцов)\n",
    "- Посмотреть на названия столбцов и типы данных\n",
    "- Выявить пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff52ba9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Загрузка датасета Open Pet Food Facts\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men.openfoodfacts.org.products.csv.gz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mskip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Образец кода для загруженного датасета:\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРазмер датасета: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\gzip.py:337\u001b[39m, in \u001b[36mGzipFile.read1\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size < \u001b[32m0\u001b[39m:\n\u001b[32m    336\u001b[39m     size = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\gzip.py:535\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.needs_input:\n\u001b[32m    534\u001b[39m     buf = \u001b[38;5;28mself\u001b[39m._fp.read(READ_BUFFER_SIZE)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     uncompress = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    537\u001b[39m     uncompress = \u001b[38;5;28mself\u001b[39m._decompressor.decompress(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Загрузка датасета Open Pet Food Facts\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('en.openfoodfacts.org.products.csv.gz', sep='\\t', on_bad_lines='skip', low_memory=True)\n",
    "\n",
    "# Образец кода для загруженного датасета:\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Столбцов: {len(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b476af3",
   "metadata": {},
   "source": [
    "## Упражнение 2: Очистка данных и предобработка\n",
    "\n",
    "### Инструкции:\n",
    "После загрузки датасета вы заметите, что в нем много столбцов и пропущенных значений. Давайте сосредоточимся на данных о пищевой ценности для нашего анализа.\n",
    "\n",
    "### Ключевые столбцы для анализа:\n",
    "- `product_name` - Название продукта\n",
    "- `categories` - Категории продукта\n",
    "- `countries` - Страны, где продается\n",
    "- `energy_100g` - Энергия на 100г (ккал)\n",
    "- `proteins_100g` - Белки на 100г\n",
    "- `carbohydrates_100g` - Углеводы на 100г\n",
    "- `fat_100g` - Жиры на 100г\n",
    "- `sugars_100g` - Сахара на 100г\n",
    "- `sodium_100g` - Натрий на 100г\n",
    "- `nutriscore_grade` - Пищевая оценка (A, B, C, D, E)\n",
    "\n",
    "### Ваши задачи:\n",
    "1. Выберите только релевантные столбцы для анализа\n",
    "2. Удалите строки с отсутствующими данными о питании\n",
    "3. Создайте чистый датасет для визуализации\n",
    "4. Изучите распределение оценок Nutri-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898f292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Очистка данных и предобработка\n",
    "# Раскомментируйте и измените этот код, когда загрузите датасет\n",
    "\n",
    "# Выберите релевантные столбцы для анализа питания\n",
    "nutritional_columns = [\n",
    "    'product_name', 'categories', 'countries',\n",
    "    'energy_100g', 'proteins_100g', 'carbohydrates_100g', \n",
    "    'fat_100g', 'sugars_100g', 'sodium_100g', 'nutriscore_grade'\n",
    "]\n",
    "\n",
    "# CODE\n",
    "\n",
    "print(\"Шаги очистки для реализации:\")\n",
    "print(\"1. Выбрать столбцы питания\")\n",
    "print(\"2. Удалить строки с пропущенными значениями\")\n",
    "print(\"3. Отфильтровать нереалистичные выбросы\")\n",
    "print(\"4. Проверить распределение Nutri-Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d775bd",
   "metadata": {},
   "source": [
    "## Упражнение 3: Базовая визуализация - Применение техник из лекции\n",
    "\n",
    "Теперь давайте применим техники визуализации, которые вы изучили на лекции! Мы начнем с простых графиков и постепенно увеличим сложность.\n",
    "\n",
    "### Упражнение 3a: Диаграммы рассеяния - Энергия против содержания белка\n",
    "\n",
    "**Цель:** Создать диаграмму рассеяния для исследования взаимосвязи между энергетической ценностью и содержанием белка в продуктах.\n",
    "\n",
    "**Инструкции:**\n",
    "1. Создайте базовую диаграмму рассеяния используя метод `.plot()` из pandas\n",
    "2. Создайте улучшенную версию используя `scatterplot()` из seaborn\n",
    "3. Добавьте цветовое кодирование по оценке Nutri-Score\n",
    "4. Интерпретируйте результаты: Какие паттерны вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93df6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Упражнение 3a: Диаграммы рассеяния\n",
    "# TODO: Реализуйте когда датасет загружен\n",
    "\n",
    "# CODE\n",
    "\n",
    "print(\"Цели упражнения 3a:\")\n",
    "print(\"1. Создать базовую диаграмму рассеяния pandas\")\n",
    "print(\"2. Улучшить с помощью seaborn и цветового кодирования\")\n",
    "print(\"3. Проанализировать паттерны между энергией и белком\")\n",
    "print(\"4. Наблюдать как Nutri-Score связан с пищевой ценностью\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ebc97",
   "metadata": {},
   "source": [
    "### Упражнение 3b: Коробчатые диаграммы - Распределение питательных веществ по Nutri-Score\n",
    "\n",
    "**Цель:** Использовать коробчатые диаграммы для сравнения пищевой ценности между различными оценками Nutri-Score.\n",
    "\n",
    "**Инструкции:**\n",
    "1. Создайте коробчатые диаграммы для энергетической ценности по оценке Nutri-Score\n",
    "2. Создайте коробчатые диаграммы для содержания сахара по оценке Nutri-Score\n",
    "3. Попробуйте комбинированную технику коробчатая диаграмма + strip plot из лекции\n",
    "4. Сравните результаты: Как различаются пищевые показатели по оценкам A-E?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Упражнение 3b: Коробчатые диаграммы\n",
    "# TODO: Реализуйте когда датасет загружен\n",
    "\n",
    "\n",
    "print(\"Цели упражнения 3b:\")\n",
    "print(\"1. Сравнить энергию по оценкам Nutri-Score\")\n",
    "print(\"2. Проанализировать паттерны содержания сахара\")\n",
    "print(\"3. Применить комбинированные техники визуализации\")\n",
    "print(\"4. Интерпретировать что делает продукты более/менее здоровыми\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551720f",
   "metadata": {},
   "source": [
    "### Упражнение 3c: Скрипичные диаграммы и KDE - Анализ распределений\n",
    "\n",
    "**Цель:** Использовать скрипичные диаграммы и KDE для анализа формы распределений питательных веществ.\n",
    "\n",
    "**Инструкции:**\n",
    "1. Создайте скрипичные диаграммы для содержания жиров по оценке Nutri-Score\n",
    "2. Используйте KDE графики для сравнения распределений белка по оценкам\n",
    "3. Экспериментируйте с обеими техниками и сравните их выводы\n",
    "4. Определите какие продукты имеют необычные пищевые профили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Упражнение 3c: Скрипичные диаграммы и KDE\n",
    "# TODO: Реализуйте когда датасет загружен\n",
    "\n",
    "# CODE\n",
    "\n",
    "print(\"Цели упражнения 3c:\")\n",
    "print(\"1. Исследовать распределения содержания жиров\")\n",
    "print(\"2. Сравнить паттерны белка используя KDE\")\n",
    "print(\"3. Выявить мультимодальные распределения\")\n",
    "print(\"4. Понять различия форм между оценками\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05168d",
   "metadata": {},
   "source": [
    "## Упражнение 4: Продвинутый многомерный анализ\n",
    "\n",
    "### Упражнение 4a: Парные графики - Взаимосвязи питательных веществ\n",
    "\n",
    "**Цель:** Использовать парные графики для исследования взаимосвязей между всеми пищевыми переменными одновременно.\n",
    "\n",
    "**Инструкции:**\n",
    "1. Создайте парный график для основных пищевых компонентов (энергия, белок, углеводы, жиры)\n",
    "2. Используйте цветовое кодирование по оценке Nutri-Score\n",
    "3. Попробуйте и гистограмму, и KDE на диагонали\n",
    "4. Определите наиболее сильные корреляции и наиболее разделимые питательные вещества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b477c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Упражнение 4a: Парные графики\n",
    "# TODO: Реализуйте когда датасет загружен\n",
    "\n",
    "# CODE\n",
    "\n",
    "print(\"Цели упражнения 4a:\")\n",
    "print(\"1. Проанализировать все пищевые взаимосвязи одновременно\")\n",
    "print(\"2. Определить наиболее сильные корреляции\")\n",
    "print(\"3. Сравнить гистограмму против KDE на диагонали\")\n",
    "print(\"4. Найти какие питательные вещества лучше всего разделяют оценки Nutri-Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc718041",
   "metadata": {},
   "source": [
    "### Упражнение 4b: Продвинутые многомерные техники\n",
    "\n",
    "**Цель:** Применить сложные методы визуализации из лекции: Кривые Эндрюса, Параллельные координаты и RadViz.\n",
    "\n",
    "**Инструкции:**\n",
    "1. Используйте Кривые Эндрюса для визуализации пищевых паттернов\n",
    "2. Создайте график Параллельные координаты для профилей питательных веществ\n",
    "3. Примените RadViz для просмотра кластеризации питательных веществ\n",
    "4. Сравните выводы от каждого метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Упражнение 4b: Продвинутые многомерные техники\n",
    "# TODO: Реализуйте когда датасет загружен\n",
    "\n",
    "# Подготовьте данные для продвинутых визуализаций\n",
    "# df_advanced = df_nutrition.sample(1000, random_state=42)  # Выборка для производительности\n",
    "\n",
    "# CODE\n",
    "\n",
    "print(\"Цели упражнения 4b:\")\n",
    "print(\"1. Применить Кривые Эндрюса для поиска пищевых паттернов\")\n",
    "print(\"2. Использовать Параллельные координаты для сравнения профилей\")\n",
    "print(\"3. Исследовать кластеризацию RadViz похожих продуктов\")\n",
    "print(\"4. Сравнить выводы от каждого продвинутого метода\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4861a",
   "metadata": {},
   "source": [
    "## Упражнения-вызовы\n",
    "\n",
    "Готовы к более продвинутым вызовам? Эти упражнения проверят ваше понимание и креативность!\n",
    "\n",
    "### Вызов 1: Анализ категорий\n",
    "**Задача:** Проанализируйте как пищевая ценность варьируется между различными категориями продуктов.\n",
    "- Извлеките и очистите столбец `categories`\n",
    "- Создайте визуализации, сравнивающие основные категории продуктов\n",
    "- Найдите какие категории имеют лучшие/худшие пищевые профили\n",
    "\n",
    "### Вызов 2: Географический анализ  \n",
    "**Задача:** Исследуйте пищевые различия между странами.\n",
    "- Разберите столбец `countries`  \n",
    "- Сравните пищевые стандарты между различными регионами\n",
    "- Определите страны с самыми здоровыми пищевыми продуктами\n",
    "\n",
    "### Вызов 3: Собственные выводы\n",
    "**Задача:** Найдите свой собственный интересный паттерн в данных.\n",
    "- Выберите аспект данных, который вас интересует\n",
    "- Примените множественные техники визуализации\n",
    "- Представьте убедительную историю о ваших находках\n",
    "\n",
    "### Вызов 4: Интерактивная панель\n",
    "**Задача:** Создайте интерактивную визуализацию (если знаете Plotly/Bokeh).\n",
    "- Разрешите фильтрацию по категории, стране или Nutri-Score\n",
    "- Включите масштабирование и наведение для деталей\n",
    "- Сделайте это полезным для анализа пищевой промышленности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пространство для упражнений-вызовов\n",
    "# Используйте эту ячейку и создайте дополнительные ячейки ниже для ваших решений вызовов\n",
    "\n",
    "# Вызов 1: Пример структуры анализа категорий\n",
    "# TODO: Реализуйте анализ категорий\n",
    "\n",
    "# Пример подхода для Вызова 1:\n",
    "# 1. Извлеките основные категории из столбца categories\n",
    "# df_clean['main_category'] = df_clean['categories'].str.split(',').str[0]\n",
    "# \n",
    "# 2. Группируйте по категориям и анализируйте средние значения питания\n",
    "# category_nutrition = df_clean.groupby('main_category')[nutrition_vars].mean()\n",
    "# \n",
    "# 3. Создайте визуализации\n",
    "# - Тепловая карта категорий против питательных веществ\n",
    "# - Коробчатые диаграммы сравнивающие категории\n",
    "# - Радарные диаграммы для профилей категорий\n",
    "\n",
    "print(\"💡 Советы для вызовов:\")\n",
    "print(\"1. Начните с исследования и очистки данных\")\n",
    "print(\"2. Выберите подходящую визуализацию для вашего вопроса\")  \n",
    "print(\"3. Всегда интерпретируйте ваши результаты\")\n",
    "print(\"4. Учитывайте вашу аудиторию при проектировании графиков\")\n",
    "print(\"5. Не забывайте правильно обрабатывать пропущенные данные\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fc873",
   "metadata": {},
   "source": [
    "## Резюме и рефлексия\n",
    "\n",
    "### Что вы практиковали:\n",
    "**Загрузка и очистка данных** - Работа с реальными грязными данными  \n",
    "**Базовая визуализация** - Диаграммы рассеяния, коробчатые диаграммы, скрипичные диаграммы  \n",
    "**Продвинутые техники** - Парные графики, кривые Эндрюса, параллельные координаты, RadViz  \n",
    "**Статистический анализ** - KDE, анализ распределений, обнаружение выбросов  \n",
    "**Многомерный анализ** - Исследование сложных взаимосвязей  \n",
    "\n",
    "### Ключевые выводы:\n",
    "1. **Реальные данные грязные** - очистка критически важна для осмысленного анализа\n",
    "2. **Множественные перспективы важны** - разные графики раскрывают разные выводы  \n",
    "3. **Цветовое кодирование мощно** - категориальные переменные добавляют глубину анализу\n",
    "4. **Продвинутые техники** - полезны для сложных многомерных взаимосвязей\n",
    "5. **Контекст имеет значение** - доменные знания помогают интерпретировать результаты\n",
    "\n",
    "### Следующие шаги:\n",
    "- Попробуйте с различными датасетами (данные ВОЗ о здоровье, экономические показатели и т.д.)\n",
    "- Изучите библиотеки интерактивной визуализации (Plotly, Bokeh)\n",
    "- Исследуйте статистическое тестирование наряду с визуализацией\n",
    "- Практикуйте рассказывание историй с данными для презентаций\n",
    "\n",
    "### Ресурсы для дальнейшего изучения:\n",
    "- **Документация Seaborn:** https://seaborn.pydata.org/\n",
    "- **Галерея Matplotlib:** https://matplotlib.org/gallery/\n",
    "- **Визуализация Pandas:** https://pandas.pydata.org/docs/user_guide/visualization.html\n",
    "- **Книги по визуализации данных:** \"The Grammar of Graphics\", \"Storytelling with Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4f325",
   "metadata": {},
   "source": [
    "## Дополнительные учебные материалы\n",
    "\n",
    "### Если вы хотите углубить знания:\n",
    "\n",
    "**Книги:**\n",
    "- \"The Grammar of Graphics\" - Leland Wilkinson (теоретические основы)\n",
    "- \"Storytelling with Data\" - Cole Nussbaumer Knaflic (практические советы)\n",
    "- \"Data Visualization: A Practical Introduction\" - Kieran Healy\n",
    "\n",
    "**Онлайн ресурсы:**\n",
    "- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html) - официальное руководство\n",
    "- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/) - примеры графиков\n",
    "- [Python Graph Gallery](https://python-graph-gallery.com/) - коллекция графиков с кодом\n",
    "\n",
    "**Видео курсы:**\n",
    "- Data Visualization with Python на Coursera\n",
    "- Matplotlib и Seaborn на YouTube\n",
    "- \"Fundamentals of Data Visualization\" на edX\n",
    "\n",
    "**Практические проекты:**\n",
    "- Анализ данных Kaggle competitions\n",
    "- Визуализация открытых данных правительства\n",
    "- Создание дашбордов для бизнес-анализа\n",
    "\n",
    "### Следующие темы для изучения:\n",
    "1. **Интерактивная визуализация:** Plotly, Bokeh, Altair\n",
    "2. **Веб-дашборды:** Streamlit, Dash\n",
    "3. **Географическая визуализация:** Folium, GeoPandas\n",
    "4. **Статистическая визуализация:** Корреляционный анализ, регрессия\n",
    "5. **Большие данные:** Datashader для работы с миллионами точек"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
